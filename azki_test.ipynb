{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facace04-70f5-4da9-96d7-27ffa4a94840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency, ttest_ind, mannwhitneyu \n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.stats.proportion import proportions_ztest \n",
    "import os\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a6138-3e0f-42e0-94cf-9e46190f64b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stage 0: Preparation ---\n",
    "print(\"--- Stage 0: Preparation ---\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 7)\n",
    "\n",
    "\n",
    "base_path = os.path.dirname(os.path.abspath(__file__))  \n",
    "output_dir = os.path.join(base_path, \"ab_test_analysis_output_v3\")\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Output directory created: {output_dir}\")\n",
    "else:\n",
    "    print(f\"Output directory already exists: {output_dir}\")\n",
    "print(\"Preparation complete.\\n\")\n",
    "\n",
    "# --- Stage 1: Loading and Initial Data Cleaning & Verification ---\n",
    "print(\"--- Stage 1: Loading and Initial Data Cleaning & Verification ---\")\n",
    "csv_file_path = os.path.join(base_path, \"data.csv\")\n",
    "\n",
    "# ALWAYS LOAD THE DATAFRAME FRESHLY\n",
    "try:\n",
    "    df_original = pd.read_csv(csv_file_path) # Load into a new variable first\n",
    "    df = df_original.copy() # Work on a copy\n",
    "    print(f\"Dataset loaded successfully from: {csv_file_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Dataset file '{csv_file_path}' not found. Please check the path.\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nInitial dataset information (df.info()):\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nFirst 5 rows of the raw dataset (df.head()):\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nInitial check for missing values (df.isnull().sum()):\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 1. Parse the 'group' column (Only if it exists)\n",
    "if 'group' in df.columns:\n",
    "    print(\"\\n'group' column found. Parsing...\")\n",
    "    def parse_group_json(json_str):\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "            return pd.Series([data['value']['group'], data['value']['operation_cost']])\n",
    "        except (json.JSONDecodeError, TypeError, KeyError):\n",
    "            return pd.Series([None, None])\n",
    "\n",
    "    df[['group_letter', 'operation_cost']] = df['group'].apply(parse_group_json)\n",
    "    df.drop('group', axis=1, inplace=True)\n",
    "    print(\"'group' column parsed into 'group_letter' and 'operation_cost'.\")\n",
    "else:\n",
    "    print(\"\\n'group' column not found. Assuming it was already parsed in a previous run.\")\n",
    "    # Check if 'group_letter' and 'operation_cost' already exist\n",
    "    if not ('group_letter' in df.columns and 'operation_cost' in df.columns):\n",
    "        print(\"ERROR: 'group' column is missing AND 'group_letter'/'operation_cost' are also missing. Cannot proceed.\")\n",
    "        exit()\n",
    "    else:\n",
    "        print(\"'group_letter' and 'operation_cost' columns already exist.\")\n",
    "\n",
    "\n",
    "# --- !!! IMPORTANT VERIFICATION STEP !!! ---\n",
    "print(\"\\n--- VERIFICATION OF GROUP ASSIGNMENT AND OPERATION COSTS ---\")\n",
    "# Ensure group_letter and operation_cost are not NaN before groupby if they were just created\n",
    "# (This shouldn't be an issue if parse_group_json handles errors by returning None,\n",
    "#  but good to be aware of. If they contain NaNs, groupby might behave unexpectedly or error)\n",
    "if df['group_letter'].isnull().any() or df['operation_cost'].isnull().any():\n",
    "    print(\"Warning: NaN values found in 'group_letter' or 'operation_cost' after parsing.\")\n",
    "    print(df[df['group_letter'].isnull() | df['operation_cost'].isnull()])\n",
    "\n",
    "group_cost_distribution = df.groupby(['group_letter', 'operation_cost'], dropna=False).size().reset_index(name='count')\n",
    "print(group_cost_distribution)\n",
    "# --- !!! END OF IMPORTANT VERIFICATION STEP !!! ---\n",
    "\n",
    "# 2. Convert 'date' column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "print(\"\\n'date' column converted to datetime type.\")\n",
    "\n",
    "# 3. Convert 'price' column to float and handle invalid entries\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "print(\"\\n'price' column converted to numeric (float) type.\")\n",
    "initial_rows = len(df)\n",
    "df.dropna(subset=['price'], inplace=True) # Remove rows with NaN price\n",
    "rows_after_price_dropna = len(df)\n",
    "if initial_rows > rows_after_price_dropna:\n",
    "    print(f\"{initial_rows - rows_after_price_dropna} rows with invalid prices were removed.\")\n",
    "else:\n",
    "    print(\"No rows with invalid prices found or removed.\")\n",
    "\n",
    "\n",
    "# 4. Handle missing values in 'user_device' and 'renewal_status'\n",
    "df['user_device'].fillna('unknown', inplace=True)\n",
    "df['renewal_status'].fillna('unknown', inplace=True)\n",
    "print(\"\\nMissing values in 'user_device' and 'renewal_status' filled with 'unknown'.\")\n",
    "\n",
    "print(\"\\nMissing values after all initial cleaning (df.isnull().sum()):\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nDataset information after initial cleaning (df.info()):\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nFirst 5 rows of the cleaned dataset (df.head()):\")\n",
    "print(df.head())\n",
    "print(\"\\nLast 5 rows of the cleaned dataset (df.tail()):\")\n",
    "print(df.tail())\n",
    "print(\"\\nUnique values in 'group_letter':\", df['group_letter'].unique())\n",
    "print(\"Unique values in 'operation_cost':\", df['operation_cost'].unique())\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accba26d-a410-4ede-941a-251dd3dd1f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Stage 2: Exploratory Data Analysis (EDA) - Task 1 (Continued) ---\n",
    "print(\"\\n--- Stage 2: Exploratory Data Analysis (EDA) ---\")\n",
    "\n",
    "if 'df' not in globals():\n",
    "    print(\"DataFrame 'df' not found. Please run Stage 1 (loading and cleaning) first.\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nDescriptive statistics for numerical columns:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nDescriptive statistics for categorical columns:\")\n",
    "print(df.describe(include=['object']))\n",
    "\n",
    "# Order for plots based on actual operation cost: A (0), C (40k), B (80k)\n",
    "group_order = ['A', 'C', 'B']\n",
    "\n",
    "# Distribution of groups (already verified, but good for visual consistency)\n",
    "plt.figure()\n",
    "sns.countplot(data=df, x='group_letter', order=group_order)\n",
    "plt.title('Distribution of Users in Different Test Groups')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.savefig(os.path.join(output_dir, \"01_group_distribution.png\"))\n",
    "plt.show()\n",
    "print(\"\\nGroup distribution (normalized):\")\n",
    "print(df['group_letter'].value_counts(normalize=True).reindex(group_order))\n",
    "\n",
    "# Distribution of order_status\n",
    "plt.figure(figsize=(10,6)) # Adjusted for better readability\n",
    "sns.countplot(data=df, y='order_status', hue='group_letter', hue_order=group_order)\n",
    "plt.title('Distribution of Order Status by Group')\n",
    "plt.xlabel('Number of Orders')\n",
    "plt.ylabel('Order Status')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"02_order_status_distribution.png\"))\n",
    "plt.show()\n",
    "print(\"\\nOrder status distribution (normalized overall):\")\n",
    "print(df['order_status'].value_counts(normalize=True))\n",
    "\n",
    "# Distribution of price\n",
    "plt.figure()\n",
    "sns.histplot(data=df, x='price', hue='group_letter', kde=True, hue_order=group_order, multiple=\"stack\")\n",
    "plt.title('Distribution of Final Insurance Price by Group')\n",
    "plt.xlabel('Price (Toman)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig(os.path.join(output_dir, \"03_price_distribution_hist.png\"))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(data=df, x='group_letter', y='price', order=group_order)\n",
    "plt.title('Box Plot of Final Insurance Price by Group')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Price (Toman)')\n",
    "plt.savefig(os.path.join(output_dir, \"04_price_distribution_boxplot.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Distribution of insurance type (type)\n",
    "print(\"\\nDistribution of Insurance Type:\")\n",
    "print(df['type'].value_counts())\n",
    "\n",
    "# Distribution of renewal_status\n",
    "plt.figure()\n",
    "sns.countplot(data=df, x='renewal_status', hue='group_letter', hue_order=group_order)\n",
    "plt.title('Distribution of Renewal Status by Group')\n",
    "plt.xlabel('Renewal Status')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"05_renewal_status_distribution.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Distribution of user_device\n",
    "plt.figure(figsize=(10,6)) # Adjusted\n",
    "sns.countplot(data=df, y='user_device', hue='group_letter', hue_order=group_order)\n",
    "plt.title('Distribution of User Device by Group')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('User Device')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"06_user_device_distribution.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Distribution of payment_method\n",
    "plt.figure()\n",
    "sns.countplot(data=df, x='payment_method', hue='group_letter', hue_order=group_order)\n",
    "plt.title('Distribution of Payment Method by Group')\n",
    "plt.xlabel('Payment Method')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig(os.path.join(output_dir, \"07_payment_method_distribution.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Distribution of voucher usage\n",
    "plt.figure()\n",
    "sns.countplot(data=df, x='voucher', hue='group_letter', hue_order=group_order)\n",
    "plt.title('Distribution of Voucher Usage by Group')\n",
    "plt.xlabel('Voucher Used (1: Yes, 0: No)')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig(os.path.join(output_dir, \"08_voucher_usage_distribution.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Voucher usage for successful orders\n",
    "plt.figure()\n",
    "# Ensure 'done' status exists, otherwise filter might result in empty df\n",
    "successful_orders_df = df[df['order_status']=='done']\n",
    "if not successful_orders_df.empty:\n",
    "    sns.countplot(data=successful_orders_df, x='voucher', hue='group_letter', hue_order=group_order)\n",
    "    plt.title('Voucher Usage in Successful Orders by Group')\n",
    "    plt.xlabel('Voucher Used (1: Yes, 0: No)')\n",
    "    plt.ylabel('Number of Successful Orders')\n",
    "    plt.savefig(os.path.join(output_dir, \"09_voucher_usage_successful_orders.png\"))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No successful orders ('done') found to plot voucher usage for successful orders.\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"EDA plots generated and saved in:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c87b01-7efa-4102-b311-956e8e6a3c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If not, you need to re-run the cleaned Stage 1 code first.\n",
    "if 'df' not in globals():\n",
    "    print(\"DataFrame 'df' not found. Please run Stage 1 (loading and cleaning) first.\")\n",
    "    # Re-run Stage 1 logic here if needed for a standalone script\n",
    "    try:\n",
    "        # Define the full path to the CSV file\n",
    "        base_path = '/home/shared/Atefeh/tn_refactor_log/az/'\n",
    "        output_dir = os.path.join(base_path, \"ab_test_analysis_output_v3\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        csv_file_path = os.path.join(base_path, \"data.csv\") # Make sure this is correct\n",
    "        df_original = pd.read_csv(csv_file_path)\n",
    "        df = df_original.copy()\n",
    "        print(f\"Dataset re-loaded successfully from: {csv_file_path} for Stage 3&4\")\n",
    "\n",
    "        if 'group' in df.columns:\n",
    "            def parse_group_json(json_str):\n",
    "                try:\n",
    "                    data = json.loads(json_str)\n",
    "                    return pd.Series([data['value']['group'], data['value']['operation_cost']])\n",
    "                except: return pd.Series([None, None])\n",
    "            df[['group_letter', 'operation_cost']] = df['group'].apply(parse_group_json)\n",
    "            df.drop('group', axis=1, inplace=True)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "        df.dropna(subset=['price'], inplace=True)\n",
    "        df['user_device'].fillna('unknown', inplace=True)\n",
    "        df['renewal_status'].fillna('unknown', inplace=True)\n",
    "        print(\"DataFrame 'df' re-loaded and cleaned for Stage 3&4.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error re-loading/cleaning df: {e}\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "print(\"\\n--- Stage 3 & 4: Calculating Metrics, Statistical Testing, and Visualization ---\")\n",
    "\n",
    "# Order for consistency in results and plots\n",
    "group_order = ['A', 'C', 'B'] # Based on 0, 40k, 80k operation cost\n",
    "\n",
    "# Calculate total users per group\n",
    "total_users_per_group = df['group_letter'].value_counts().reindex(group_order).fillna(0)\n",
    "\n",
    "# Filter for successful orders\n",
    "successful_orders = df[df['order_status'] == 'done'].copy()\n",
    "\n",
    "# 1. Conversion Rate (CR)\n",
    "conversions_per_group = successful_orders['group_letter'].value_counts().reindex(group_order).fillna(0)\n",
    "conversion_rate = (conversions_per_group / total_users_per_group).fillna(0)\n",
    "\n",
    "# 2. Average Order Value (AOV) - based on final price paid\n",
    "aov = successful_orders.groupby('group_letter')['price'].mean().reindex(group_order).fillna(0)\n",
    "\n",
    "# 3. Total Revenue\n",
    "total_revenue = successful_orders.groupby('group_letter')['price'].sum().reindex(group_order).fillna(0)\n",
    "\n",
    "# 4. Revenue Per User (RPU)\n",
    "rpu = (total_revenue / total_users_per_group).fillna(0)\n",
    "\n",
    "# 5. Total Operational Fee Collected\n",
    "total_operational_fee = successful_orders.groupby('group_letter')['operation_cost'].sum().reindex(group_order).fillna(0)\n",
    "\n",
    "# Create a summary DataFrame for results\n",
    "summary_df = pd.DataFrame({\n",
    "    'Total Users': total_users_per_group,\n",
    "    'Successful Purchases': conversions_per_group,\n",
    "    'Conversion Rate (CR)': conversion_rate,\n",
    "    'Average Order Value (AOV)': aov,\n",
    "    'Total Revenue': total_revenue,\n",
    "    'Revenue Per User (RPU)': rpu,\n",
    "    'Total Operational Fee Collected': total_operational_fee\n",
    "})\n",
    "summary_df = summary_df[['Total Users', 'Successful Purchases', 'Conversion Rate (CR)',\n",
    "                         'Average Order Value (AOV)', 'Total Revenue', 'Revenue Per User (RPU)',\n",
    "                         'Total Operational Fee Collected']] # Ensure column order\n",
    "\n",
    "print(\"\\nSummary of A/B Test Results:\")\n",
    "print(summary_df)\n",
    "\n",
    "# --- Statistical Significance Testing ---\n",
    "print(\"\\n--- Statistical Significance Testing ---\")\n",
    "alpha = 0.05 # Significance level\n",
    "\n",
    "# 1. Conversion Rate (CR) - using proportions_ztest\n",
    "print(\"\\nConversion Rate (CR) Comparisons:\")\n",
    "for i in range(len(group_order)):\n",
    "    for j in range(i + 1, len(group_order)):\n",
    "        group1_letter = group_order[i]\n",
    "        group2_letter = group_order[j]\n",
    "\n",
    "        count = [conversions_per_group.get(group1_letter, 0), conversions_per_group.get(group2_letter, 0)]\n",
    "        nobs = [total_users_per_group.get(group1_letter, 0), total_users_per_group.get(group2_letter, 0)]\n",
    "\n",
    "        if nobs[0] == 0 or nobs[1] == 0:\n",
    "            print(f\"Skipping CR comparison between {group1_letter} and {group2_letter} due to zero observations in one group.\")\n",
    "            continue\n",
    "\n",
    "        z_stat, p_value = proportions_ztest(count, nobs, alternative='two-sided')\n",
    "        print(f\"CR Comparison between {group1_letter} and {group2_letter}: Z-stat={z_stat:.3f}, P-value={p_value:.4f}\", end=\"\")\n",
    "        if p_value < alpha:\n",
    "            print(f\" (Significant at alpha={alpha})\")\n",
    "        else:\n",
    "            print(f\" (Not significant at alpha={alpha})\")\n",
    "\n",
    "# 2. Average Order Value (AOV) - using Mann-Whitney U\n",
    "print(\"\\nAverage Order Value (AOV) Comparisons (Mann-Whitney U):\")\n",
    "aov_data = {}\n",
    "for letter in group_order:\n",
    "    aov_data[letter] = successful_orders[successful_orders['group_letter'] == letter]['price']\n",
    "\n",
    "for i in range(len(group_order)):\n",
    "    for j in range(i + 1, len(group_order)):\n",
    "        group1_letter = group_order[i]\n",
    "        group2_letter = group_order[j]\n",
    "\n",
    "        data1 = aov_data[group1_letter]\n",
    "        data2 = aov_data[group2_letter]\n",
    "\n",
    "        if len(data1) < 1 or len(data2) < 1 :\n",
    "            print(f\"Skipping AOV comparison between {group1_letter} and {group2_letter} due to insufficient data.\")\n",
    "            continue\n",
    "        # Perform test only if both groups have data for AOV\n",
    "        if not data1.empty and not data2.empty:\n",
    "            try:\n",
    "                u_stat, p_value = mannwhitneyu(data1, data2, alternative='two-sided')\n",
    "                print(f\"AOV Comparison between {group1_letter} and {group2_letter}: U-stat={u_stat:.0f}, P-value={p_value:.4f}\", end=\"\")\n",
    "                if p_value < alpha:\n",
    "                    print(f\" (Significant at alpha={alpha})\")\n",
    "                else:\n",
    "                    print(f\" (Not significant at alpha={alpha})\")\n",
    "            except ValueError as e: # Handles cases like all values being identical\n",
    "                print(f\"Could not compare AOV for {group1_letter} and {group2_letter}: {e}\")\n",
    "        else:\n",
    "            print(f\"Skipping AOV comparison between {group1_letter} and {group2_letter} due to one or both groups having no successful orders.\")\n",
    "\n",
    "\n",
    "# Visualizing Key Metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "fig.suptitle('Comparison of Key Metrics Across Groups (Order: A, C, B)', fontsize=18, y=1.02)\n",
    "\n",
    "summary_df['Conversion Rate (CR)'].plot(kind='bar', ax=axes[0,0], color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[0,0].set_title('Conversion Rate (CR)', fontsize=14)\n",
    "axes[0,0].set_ylabel('Rate', fontsize=12)\n",
    "axes[0,0].tick_params(axis='x', rotation=0, labelsize=10)\n",
    "axes[0,0].grid(axis='y', linestyle='--')\n",
    "\n",
    "summary_df['Average Order Value (AOV)'].plot(kind='bar', ax=axes[0,1], color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[0,1].set_title('Average Order Value (AOV)', fontsize=14)\n",
    "axes[0,1].set_ylabel('Price (Toman)', fontsize=12)\n",
    "axes[0,1].tick_params(axis='x', rotation=0, labelsize=10)\n",
    "axes[0,1].grid(axis='y', linestyle='--')\n",
    "\n",
    "summary_df['Revenue Per User (RPU)'].plot(kind='bar', ax=axes[1,0], color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[1,0].set_title('Revenue Per User (RPU)', fontsize=14)\n",
    "axes[1,0].set_ylabel('Price (Toman)', fontsize=12)\n",
    "axes[1,0].tick_params(axis='x', rotation=0, labelsize=10)\n",
    "axes[1,0].grid(axis='y', linestyle='--')\n",
    "\n",
    "summary_df['Total Revenue'].plot(kind='bar', ax=axes[1,1], color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "axes[1,1].set_title('Total Revenue', fontsize=14)\n",
    "axes[1,1].set_ylabel('Price (Toman)', fontsize=12)\n",
    "axes[1,1].tick_params(axis='x', rotation=0, labelsize=10)\n",
    "axes[1,1].grid(axis='y', linestyle='--')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.savefig(os.path.join(output_dir, \"10_key_metrics_comparison.png\"))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Analysis by existing features (Example: renewal_status)\n",
    "print(\"\\n--- CR Analysis by Renewal Status ---\")\n",
    "cr_by_renewal = df.groupby(['group_letter', 'renewal_status'])['order_status'].apply(lambda x: (x == 'done').mean()).unstack().reindex(group_order)\n",
    "print(cr_by_renewal)\n",
    "\n",
    "ax_cr_renewal = cr_by_renewal.plot(kind='bar', figsize=(14,8))\n",
    "ax_cr_renewal.set_title('Conversion Rate by Group and Renewal Status', fontsize=16)\n",
    "ax_cr_renewal.set_ylabel('Conversion Rate', fontsize=12)\n",
    "ax_cr_renewal.set_xlabel('Group', fontsize=12)\n",
    "ax_cr_renewal.tick_params(axis='x', rotation=0, labelsize=10)\n",
    "ax_cr_renewal.tick_params(axis='y', labelsize=10)\n",
    "ax_cr_renewal.legend(title='Renewal Status', fontsize=10)\n",
    "ax_cr_renewal.grid(axis='y', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"11_cr_by_renewal_status.png\"))\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- AOV Analysis by Renewal Status ---\")\n",
    "# Ensure successful_orders is not empty\n",
    "if not successful_orders.empty:\n",
    "    aov_by_renewal = successful_orders.groupby(['group_letter', 'renewal_status'])['price'].mean().unstack().reindex(group_order)\n",
    "    print(aov_by_renewal)\n",
    "\n",
    "    ax_aov_renewal = aov_by_renewal.plot(kind='bar', figsize=(14,8))\n",
    "    ax_aov_renewal.set_title('Average Order Value by Group and Renewal Status', fontsize=16)\n",
    "    ax_aov_renewal.set_ylabel('AOV (Toman)', fontsize=12)\n",
    "    ax_aov_renewal.set_xlabel('Group', fontsize=12)\n",
    "    ax_aov_renewal.tick_params(axis='x', rotation=0, labelsize=10)\n",
    "    ax_aov_renewal.tick_params(axis='y', labelsize=10)\n",
    "    ax_aov_renewal.legend(title='Renewal Status', fontsize=10)\n",
    "    ax_aov_renewal.grid(axis='y', linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"12_aov_by_renewal_status.png\"))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No successful orders to analyze AOV by renewal status.\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"Metrics calculation and statistical testing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d0936-d2e6-46bb-9014-c0bf53374212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
